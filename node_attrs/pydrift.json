{
 "PRed":[
  {
   "PR":{
    "__lazy_json__":"pr_json/426025070.json"
   },
   "data":{
    "bot_rerun":false,
    "migrator_name":"Version",
    "migrator_version":0,
    "version":"0.2.2"
   },
   "keys":[
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR":{
    "__lazy_json__":"pr_json/429168124.json"
   },
   "data":{
    "bot_rerun":false,
    "migrator_name":"Version",
    "migrator_version":0,
    "version":"0.2.3"
   },
   "keys":[
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR":{
    "__lazy_json__":"pr_json/441049258.json"
   },
   "data":{
    "bot_rerun":false,
    "migrator_name":"Version",
    "migrator_version":0,
    "version":"0.2.5"
   },
   "keys":[
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  }
 ],
 "archived":false,
 "bad":false,
 "conda-forge.yml":{},
 "feedstock_name":"pydrift",
 "hash_type":"sha256",
 "meta_yaml":{
  "about":{
   "description":"How do we measure the degradation of a machine learning process?\nWhy does the performance of our predictive models decrease? Maybe it is\nthat a data source has changed (one or more variables) or maybe what\nchanges is the relationship of these variables with the target we want\nto predict. `pydrift` tries to facilitate this task to the data scientist,\nperforming this kind of checks and somehow measuring that degradation.\n",
   "dev_url":"https://github.com/sergiocalde94/Data-And-Model-Drift-Checker/",
   "doc_url":"https://sergiocalde94.github.io/Data-And-Model-Drift-Checker/",
   "home":"https://github.com/sergiocalde94/Data-And-Model-Drift-Checker",
   "license":"MIT",
   "license_family":"MIT",
   "license_file":"LICENSE",
   "summary":"Measuring the degradation of a machine learning model"
  },
  "build":{
   "noarch":"python",
   "number":"0",
   "script":"-m pip install . -vv"
  },
  "extra":{
   "recipe-maintainers":[
    "sergiocalde94",
    "sergiocalde94",
    "sergiocalde94"
   ]
  },
  "package":{
   "name":"pydrift",
   "version":"0.2.5"
  },
  "requirements":{
   "host":[
    "python",
    "pip",
    "poetry",
    "python",
    "pip",
    "poetry",
    "python",
    "pip",
    "poetry"
   ],
   "run":[
    "python",
    "pip",
    "catboost >=0.23",
    "pandas >=1.0.3",
    "scikit-learn >=0.23.1",
    "shap >=0.35.0",
    "typing-extensions >=3.7.4",
    "python",
    "pip",
    "catboost >=0.23",
    "pandas >=1.0.3",
    "scikit-learn >=0.23.1",
    "shap >=0.35.0",
    "typing-extensions >=3.7.4",
    "python",
    "pip",
    "catboost >=0.23",
    "pandas >=1.0.3",
    "scikit-learn >=0.23.1",
    "shap >=0.35.0",
    "typing-extensions >=3.7.4"
   ]
  },
  "source":{
   "sha256":"786202a22d96797a611d3f86f4fb0f5aae601f1f61e01a09d5dee3ce9b679c19",
   "url":"https://pypi.io/packages/source/p/pydrift/pydrift-0.2.5.tar.gz"
  },
  "test":{
   "imports":[
    "pydrift",
    "pydrift",
    "pydrift"
   ]
  }
 },
 "name":"pydrift",
 "new_version":"0.2.5",
 "new_version_attempts":{
  "0.2.2":1,
  "0.2.3":1,
  "0.2.5":1
 },
 "new_version_errors":{},
 "pinning_version":"2020.06.24.16.31.11",
 "raw_meta_yaml":"{% set name = \"pydrift\" %}\n{% set version = \"0.2.5\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz\n  sha256: 786202a22d96797a611d3f86f4fb0f5aae601f1f61e01a09d5dee3ce9b679c19\n\nbuild:\n  noarch: python\n  number: 0\n  script: {{ PYTHON }} -m pip install . -vv\n\nrequirements:\n  host:\n    - python\n    - pip\n    - poetry\n  run:\n    - python\n    - pip\n    - catboost >=0.23\n    - pandas >=1.0.3\n    - scikit-learn >=0.23.1\n    - shap >=0.35.0\n    - typing-extensions >=3.7.4\n\ntest:\n  imports:\n    - pydrift\n\nabout:\n  home: https://github.com/sergiocalde94/Data-And-Model-Drift-Checker\n  license: MIT\n  license_family: MIT\n  license_file: LICENSE\n  summary: Measuring the degradation of a machine learning model\n\n  description: |\n    How do we measure the degradation of a machine learning process?\n    Why does the performance of our predictive models decrease? Maybe it is\n    that a data source has changed (one or more variables) or maybe what\n    changes is the relationship of these variables with the target we want\n    to predict. `pydrift` tries to facilitate this task to the data scientist,\n    performing this kind of checks and somehow measuring that degradation.\n  doc_url: https://sergiocalde94.github.io/Data-And-Model-Drift-Checker/\n  dev_url: https://github.com/sergiocalde94/Data-And-Model-Drift-Checker/\n\nextra:\n  recipe-maintainers:\n    - sergiocalde94\n",
 "req":{
  "__set__":true,
  "elements":[
   "catboost",
   "pandas",
   "pip",
   "poetry",
   "python",
   "scikit-learn",
   "shap",
   "typing-extensions"
  ]
 },
 "requirements":{
  "build":{
   "__set__":true,
   "elements":[]
  },
  "host":{
   "__set__":true,
   "elements":[
    "pip",
    "poetry",
    "python"
   ]
  },
  "run":{
   "__set__":true,
   "elements":[
    "catboost",
    "pandas",
    "pip",
    "python",
    "scikit-learn",
    "shap",
    "typing-extensions"
   ]
  },
  "test":{
   "__set__":true,
   "elements":[]
  }
 },
 "smithy_version":"No azure token. Create a token and\nput it in ~/.conda-smithy/azure.token\n3.7.3\n",
 "strong_exports":false,
 "total_requirements":{
  "build":{
   "__set__":true,
   "elements":[]
  },
  "host":{
   "__set__":true,
   "elements":[
    "pip",
    "poetry",
    "python"
   ]
  },
  "run":{
   "__set__":true,
   "elements":[
    "catboost >=0.23",
    "pandas >=1.0.3",
    "pip",
    "python",
    "scikit-learn >=0.23.1",
    "shap >=0.35.0",
    "typing-extensions >=3.7.4"
   ]
  },
  "test":{
   "__set__":true,
   "elements":[]
  }
 },
 "url":"https://pypi.io/packages/source/p/pydrift/pydrift-0.2.1.tar.gz",
 "version":"0.2.5"
}